# TraceML

A simple CLI tool to automatically trace PyTorch training memory usage.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)  
[![GitHub Stars](https://img.shields.io/github/stars/abhinavsriva/trace_ml?style=social)](https://github.com/abhinavsriva/trace_ml/stargazers)

---

## ğŸ’¡ The Problem

Training large machine learning models often feels like a black box. One minute everything's running â€” the next, you're staring at a cryptic `"CUDA out of memory"` error.  

Pinpointing *which* part of the model is consuming too much memory or slowing things down is frustrating and time-consuming. Traditional profiling tools can be overly complex or lack the granularity deep learning developers need.

---

## âœ¨ Why TraceML?

`traceml` is a lightweight CLI tool to instrument your PyTorch training scripts and get real-time, granular insights into:

- System and process-level CPU & RAM usage  
- PyTorch layer-level memory allocation (via `gc` or decorator/instance tracing)

All shown live in your terminal â€” no config, no setup, just plug-and-trace.

---

## ğŸ“¦ Installation

```bash
pip install -e .
```

---

## ğŸš€ Usage

```bash
traceml run <your_training_script.py>
```

TraceML wraps your training script and prints memory insights to the terminal as your model trains.


### ğŸ” Examples

```bash
# Default: garbage collection-based tracing (no changes to code needed)
traceml run src/examples/tracing_with_gc

# Trace an explicitly defined model instance (e.g., functional API or Sequential model)
traceml run src/examples/tracing_with_model_instance

# Trace a model using a class decorator (recommended for structured training code)
traceml run src/examples/tracing_with_class_decorator
```


---

## âœ… Current Features

- ğŸ“Š **Live CPU & RAM usage** (System + Current Process)  
- ğŸ” **PyTorch layer-level memory tracking**:
  - âœ… Default: via `gc` scanning (zero setup)
  - ğŸ§  Via `@trace_model` class decorator
  - ğŸ”§ Via `trace_model_instance()` function for manual model instance tracing
- ğŸ® **Live GPU memory & utilization tracking** (per device)
- ğŸ“¦ **Model memory summaries** (per-layer + total)
- ğŸ§¾ **Historical snapshot viewer** with scrollable panel

---

## ğŸ”­ Coming Soon

- ğŸ¯ **Activation & gradient memory tracking**
- ğŸ“’ **Jupyter Notebook support**
- ğŸ’¾ **Export logs as JSON / CSV**

---

## ğŸ™Œ Contribute & Feedback

Found it useful? Please provide â­ to the repo.  
Got ideas, feedback, or feature requests? I would love to hear from you.

ğŸ“§ Email: [abhinavsriva@gmail.com](mailto:abhinavsriva@gmail.com)
